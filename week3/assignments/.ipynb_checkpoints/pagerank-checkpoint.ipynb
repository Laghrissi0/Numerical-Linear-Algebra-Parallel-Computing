{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d64ccf",
   "metadata": {},
   "source": [
    "Use this cell for all your imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40623a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scholarly\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f305b",
   "metadata": {},
   "source": [
    "You will be working with the file data.txt. Use this cell to load its content into the appropriate data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be42fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a8af4",
   "metadata": {},
   "source": [
    "Use this cell to normalize the matrix as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e612783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "N = int(input())\n",
    "M = np.zeros((N, N))\n",
    "def normalize_matrix(M):\n",
    "    row_sums = np.sum(M, axis=1)\n",
    "    return M / row_sums[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ee89a",
   "metadata": {},
   "source": [
    "Apply the PageRank algorithm to the matrix you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9319ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(M, num_iterations=100, d=0.85):\n",
    "    N = M.shape[1]\n",
    "    v = np.random.rand(N, 1)\n",
    "    v = v / np.linalg.norm(v, 1)\n",
    "    M_norm = normalize_matrix(M)\n",
    "    M_hat = d * M_norm + (1 - d) / N * np.ones((N, N))\n",
    "    for i in range(num_iterations):\n",
    "        v = M_hat @ v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005047ad",
   "metadata": {},
   "source": [
    "Output a list of the 100 most important papers along with their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.txt', 'r') as f:\n",
    "    paper_titles = f.readlines()\n",
    "paper_titles = [title.strip() for title in paper_titles]\n",
    "\n",
    "h_scores = []\n",
    "for title in paper_titles:\n",
    "    try:\n",
    "        search_query = scholarly.search_pubs(title)\n",
    "        paper = next(search_query)\n",
    "        citations = paper.citedby\n",
    "        h_score = citations / len(paper.bib['author'])\n",
    "        h_scores.append((title, h_score))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "h_scores_sorted = sorted(h_scores, key=lambda x: x[1], reverse=True)\n",
    "top_100_papers = h_scores_sorted[:100]\n",
    "\n",
    "# Print the top 100 papers and their h-scores\n",
    "for i, paper in enumerate(top_100_papers):\n",
    "    print(f\"{i+1}. {paper[0]} - h-score: {paper[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba2208",
   "metadata": {},
   "source": [
    "Visualize your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25affee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.from_numpy_array(M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
